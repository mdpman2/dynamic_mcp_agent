# -*- coding: utf-8 -*-
"""
Advanced Hybrid Tool Registry with Multi-layer Search

ì´ ëª¨ë“ˆì€ MCP ë„êµ¬ë“¤ì„ ì¸ë±ì‹±í•˜ê³  ë‹¤ì¸µ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬
ì‚¬ìš©ì ì¿¼ë¦¬ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ê²€ìƒ‰í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì „ëµ (5ë‹¨ê³„ + RRF):
1ï¸âƒ£ BM25 (ë¹ ë¥´ê³  ë¬´ë£Œ) - í‚¤ì›Œë“œ ë§¤ì¹­
2ï¸âƒ£ Sentence-Transformers (ë¡œì»¬, ë‹¤êµ­ì–´) - ì˜ë¯¸ë¡ ì  ìœ ì‚¬ì„±
3ï¸âƒ£ ğŸ”€ RRF (Reciprocal Rank Fusion) - BM25 + Sentence ê²°ê³¼ í†µí•©
4ï¸âƒ£ MCP Registry API (ê³µì‹) - ì™¸ë¶€ ë„êµ¬ ë°œê²¬
5ï¸âƒ£ LLM ì¶”ë¡  (GPT-5.2) - ë³µì¡í•œ ì¿¼ë¦¬ í•´ì„ (í•„ìš”ì‹œì—ë§Œ)

v3.0.0 ì—…ë°ì´íŠ¸ (2026-02-26):
- [NEW] Reciprocal Rank Fusion (RRF) í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜
- [NEW] httpx ê¸°ë°˜ ë¹„ë™ê¸° HTTP (aiohttp ëŒ€ì²´, Streamable HTTP ì§€ì›)
- [CHANGED] LLM ê²€ìƒ‰ ê¸°ë³¸ ëª¨ë¸ gpt-5 â†’ gpt-5.2
- [CHANGED] í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì— RRF ì ìˆ˜ ê¸°ë°˜ í†µí•© ì ìš©

v2.0.0 ì—…ë°ì´íŠ¸ (2026-02-07):
- [BREAKING] AzureOpenAI í´ë¼ì´ì–¸íŠ¸ â†’ OpenAI + base_url ë°©ì‹ìœ¼ë¡œ ì „í™˜
- [CHANGED] LLM ê²€ìƒ‰ ê¸°ë³¸ ëª¨ë¸ gpt-4.1 â†’ gpt-5
- [CHANGED] ê¸°ë³¸ API ë²„ì „ 2024-08-01-preview â†’ preview

ì°¸ê³ : https://github.com/modelcontextprotocol/registry
"""

import os
import re
import time
import inspect
import logging
import asyncio
import numpy as np
from typing import Dict, List, Any, Optional, Tuple, TYPE_CHECKING
from pathlib import Path

from rank_bm25 import BM25Okapi
from openai import OpenAI
from dotenv import load_dotenv

if TYPE_CHECKING:
    from sentence_transformers import SentenceTransformer as SentenceTransformerType

# ì„ íƒì  ì„í¬íŠ¸: Sentence-Transformers
try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    SentenceTransformer = None

# ì„ íƒì  ì„í¬íŠ¸: httpx (ë¹„ë™ê¸° HTTP - aiohttp ëŒ€ì²´)
try:
    import httpx
    HTTPX_AVAILABLE = True
except ImportError:
    HTTPX_AVAILABLE = False
    httpx = None

# í•˜ìœ„ í˜¸í™˜ì„±: aiohttp í´ë°±
try:
    import aiohttp
    AIOHTTP_AVAILABLE = True
except ImportError:
    AIOHTTP_AVAILABLE = False
    aiohttp = None

# í˜„ì¬ í´ë”ì˜ .envë§Œ ë¡œë“œ (ìƒìœ„ í´ë” ë¬´ì‹œ)
env_path = Path(__file__).parent.parent / ".env"
load_dotenv(dotenv_path=env_path, override=True)
logger = logging.getLogger(__name__)

# ì‚¬ì „ ì»´íŒŒì¼ëœ ì •ê·œì‹ íŒ¨í„´ (í† í°í™” ì„±ëŠ¥ ìµœì í™”)
_RE_KOREAN = re.compile(r'[\uac00-\ud7a3]+')
_RE_ENGLISH = re.compile(r'[a-z0-9]+')


class MCPRegistryClient:
    """
    ê³µì‹ MCP Registry API í´ë¼ì´ì–¸íŠ¸

    MCP RegistryëŠ” ì»¤ë®¤ë‹ˆí‹° ê¸°ë°˜ì˜ MCP ì„œë²„ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì…ë‹ˆë‹¤.
    https://registry.modelcontextprotocol.io

    API ë¬¸ì„œ: https://registry.modelcontextprotocol.io/docs
    """

    BASE_URL = "https://registry.modelcontextprotocol.io"
    API_VERSION = "v0.1"
    DEFAULT_TIMEOUT = 10

    def __init__(self, cache_ttl: int = 3600):
        self._cache: Dict[str, Any] = {}
        self._cache_time: Dict[str, float] = {}
        self._cache_ttl = cache_ttl
        self._enabled = HTTPX_AVAILABLE or AIOHTTP_AVAILABLE

        if not self._enabled:
            logger.warning("httpx/aiohttpê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ MCP Registry APIê°€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

    def _build_url(self, path: str) -> str:
        """API URLì„ êµ¬ì„±í•©ë‹ˆë‹¤."""
        return f"{self.BASE_URL}/{self.API_VERSION}/{path}"

    def _get_cached(self, key: str) -> Optional[Any]:
        """ìºì‹œëœ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if key in self._cache and time.time() - self._cache_time.get(key, 0) < self._cache_ttl:
            return self._cache[key]
        return None

    def _set_cache(self, key: str, value: Any) -> None:
        """ìºì‹œì— ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        self._cache[key] = value
        self._cache_time[key] = time.time()

    async def search_servers(self, query: str, limit: int = 10) -> List[Dict[str, Any]]:
        """MCP Registryì—ì„œ ì„œë²„ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. (httpx ìš°ì„ , aiohttp í´ë°±)"""
        if not self._enabled:
            return []

        cache_key = f"search:{query}:{limit}"
        cached = self._get_cached(cache_key)
        if cached is not None:
            return cached

        try:
            if HTTPX_AVAILABLE:
                async with httpx.AsyncClient(timeout=self.DEFAULT_TIMEOUT) as client:
                    response = await client.get(
                        self._build_url("servers"),
                        params={"search": query, "limit": limit}
                    )
                    if response.status_code == 200:
                        servers = response.json().get("servers", [])
                        self._set_cache(cache_key, servers)
                        logger.info(f"MCP Registry ê²€ìƒ‰ ì„±ê³µ: '{query}' â†’ {len(servers)}ê°œ")
                        return servers
                    logger.warning(f"MCP Registry ê²€ìƒ‰ ì‹¤íŒ¨: HTTP {response.status_code}")
                    return []
            elif AIOHTTP_AVAILABLE:
                async with aiohttp.ClientSession() as session:
                    async with session.get(
                        self._build_url("servers"),
                        params={"search": query, "limit": limit},
                        timeout=aiohttp.ClientTimeout(total=self.DEFAULT_TIMEOUT)
                    ) as response:
                        if response.status == 200:
                            servers = (await response.json()).get("servers", [])
                            self._set_cache(cache_key, servers)
                            logger.info(f"MCP Registry ê²€ìƒ‰ ì„±ê³µ: '{query}' â†’ {len(servers)}ê°œ")
                            return servers
                        logger.warning(f"MCP Registry ê²€ìƒ‰ ì‹¤íŒ¨: HTTP {response.status}")
                        return []
        except asyncio.TimeoutError:
            logger.warning("MCP Registry ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ")
        except Exception as e:
            logger.error(f"MCP Registry ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

    def search_servers_sync(self, query: str, limit: int = 10) -> List[Dict[str, Any]]:
        """ë™ê¸° ë²„ì „ì˜ ì„œë²„ ê²€ìƒ‰"""
        try:
            return asyncio.run(self.search_servers(query, limit))
        except RuntimeError:
            # ì´ë¯¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì‹¤í–‰ ì¤‘ì¸ ê²½ìš° ìƒˆ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as pool:
                return pool.submit(asyncio.run, self.search_servers(query, limit)).result(timeout=15)
        except Exception as e:
            logger.error(f"MCP Registry ë™ê¸° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    async def get_server_details(self, server_name: str) -> Optional[Dict[str, Any]]:
        """ì„œë²„ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (httpx ìš°ì„ , aiohttp í´ë°±)"""
        if not self._enabled:
            return None

        try:
            from urllib.parse import quote
            encoded_name = quote(server_name, safe='')
            url = self._build_url(f"servers/{encoded_name}/versions/latest")

            if HTTPX_AVAILABLE:
                async with httpx.AsyncClient(timeout=self.DEFAULT_TIMEOUT) as client:
                    response = await client.get(url)
                    return response.json() if response.status_code == 200 else None
            elif AIOHTTP_AVAILABLE:
                async with aiohttp.ClientSession() as session:
                    async with session.get(
                        url, timeout=aiohttp.ClientTimeout(total=self.DEFAULT_TIMEOUT)
                    ) as response:
                        return await response.json() if response.status == 200 else None
        except Exception as e:
            logger.error(f"MCP Registry ìƒì„¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None

    async def list_all_servers(self, limit: int = 30) -> List[Dict[str, Any]]:
        """ì„œë²„ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤ (ê²€ìƒ‰ ì—†ì´). (httpx ìš°ì„ , aiohttp í´ë°±)"""
        if not self._enabled:
            return []

        try:
            params = {"limit": limit, "version": "latest"}
            if HTTPX_AVAILABLE:
                async with httpx.AsyncClient(timeout=self.DEFAULT_TIMEOUT) as client:
                    response = await client.get(
                        self._build_url("servers"), params=params
                    )
                    return response.json().get("servers", []) if response.status_code == 200 else []
            elif AIOHTTP_AVAILABLE:
                async with aiohttp.ClientSession() as session:
                    async with session.get(
                        self._build_url("servers"),
                        params=params,
                        timeout=aiohttp.ClientTimeout(total=self.DEFAULT_TIMEOUT)
                    ) as response:
                        return (await response.json()).get("servers", []) if response.status == 200 else []
        except Exception as e:
            logger.error(f"MCP Registry ì„œë²„ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []


class HybridToolRegistry:
    """
    ë‹¤ì¸µ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + RRF ê¸°ë°˜ ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬

    ê²€ìƒ‰ ê³„ì¸µ:
    1. BM25 (í‚¤ì›Œë“œ ë§¤ì¹­) - ë¹ ë¥´ê³  ë¬´ë£Œ
    2. Sentence-Transformers (ë¡œì»¬ ì„ë² ë”©) - ë‹¤êµ­ì–´ ì§€ì›, ì˜ë¯¸ë¡ ì 
    3. MCP Registry API (ì™¸ë¶€) - ìƒˆë¡œìš´ ë„êµ¬ ë°œê²¬
    4. GPT-5.2 LLM (ì¶”ë¡ ) - ë³µì¡í•œ ì¿¼ë¦¬
    5. RRF (Reciprocal Rank Fusion) - ë‹¤ì¸µ ê²°ê³¼ í†µí•©

    Attributes:
        _tools: ë„êµ¬ ì´ë¦„ì„ í‚¤ë¡œ í•˜ëŠ” ë„êµ¬ ë”•ì…”ë„ˆë¦¬
        _descriptions: ê° ë„êµ¬ì˜ ì„¤ëª… ëª©ë¡
        _tool_names: ë“±ë¡ëœ ë„êµ¬ ì´ë¦„ ëª©ë¡
        _bm25: BM25 ê²€ìƒ‰ ì¸ë±ìŠ¤
        _sentence_model: Sentence-Transformers ëª¨ë¸
        _mcp_registry: MCP Registry API í´ë¼ì´ì–¸íŠ¸
    """

    # ê²€ìƒ‰ ì „ëµ ìƒìˆ˜
    BM25_CONFIDENCE_THRESHOLD = 5.0
    EMBEDDING_SIMILARITY_THRESHOLD = 0.65  # Sentence-Transformersìš© ì„ê³„ê°’ (ë‚®ì¶¤)
    RRF_K = 60  # Reciprocal Rank Fusion íŒŒë¼ë¯¸í„° (k)

    # ì¶”ì²œ ë‹¤êµ­ì–´ ëª¨ë¸ (í•œêµ­ì–´ í¬í•¨)
    DEFAULT_SENTENCE_MODEL = "paraphrase-multilingual-MiniLM-L12-v2"

    def __init__(
        self,
        azure_endpoint: Optional[str] = None,
        api_key: Optional[str] = None,
        api_version: Optional[str] = None,
        sentence_model: Optional[str] = None,
        enable_mcp_registry: bool = True,
        mcp_registry_cache_ttl: int = 3600
    ):
        """
        í•˜ì´ë¸Œë¦¬ë“œ ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Args:
            azure_endpoint: Azure OpenAI ì—”ë“œí¬ì¸íŠ¸
            api_key: API í‚¤
            api_version: API ë²„ì „
            sentence_model: Sentence-Transformers ëª¨ë¸ëª… (Noneì´ë©´ ê¸°ë³¸ ë‹¤êµ­ì–´ ëª¨ë¸)
            enable_mcp_registry: MCP Registry API ì‚¬ìš© ì—¬ë¶€
            mcp_registry_cache_ttl: MCP Registry ìºì‹œ TTL (ì´ˆ)
        """
        # ë„êµ¬ ì €ì¥ì†Œ
        self._tools: Dict[str, Any] = {}
        self._descriptions: List[str] = []
        self._tool_names: List[str] = []
        self._tool_metadata: Dict[str, Dict[str, Any]] = {}

        # BM25 ì¸ë±ìŠ¤
        self._bm25: Optional[BM25Okapi] = None

        # Sentence-Transformers (ë¡œì»¬ ë‹¤êµ­ì–´ ì„ë² ë”©)
        self._sentence_model: Optional["SentenceTransformerType"] = None
        self._sentence_model_name = sentence_model or self.DEFAULT_SENTENCE_MODEL
        self._sentence_embeddings: Optional[np.ndarray] = None
        self._init_sentence_transformers()

        # MCP Registry API
        self._mcp_registry: Optional[MCPRegistryClient] = None
        self._mcp_registry_enabled = enable_mcp_registry
        if enable_mcp_registry:
            self._mcp_registry = MCPRegistryClient(cache_ttl=mcp_registry_cache_ttl)

        # Azure OpenAI v1 API í´ë¼ì´ì–¸íŠ¸ (LLMìš©)
        self._azure_endpoint = azure_endpoint or os.getenv("AZURE_OPENAI_ENDPOINT")
        self._api_key = api_key or os.getenv("AZURE_OPENAI_API_KEY")
        self._api_version = api_version or os.getenv("AZURE_OPENAI_API_VERSION", "preview")
        self._llm_model = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "gpt-5.2")
        self._openai_client: Optional[OpenAI] = None
        self._init_openai_client()

        # ê²€ìƒ‰ í†µê³„
        self._search_stats = {
            "bm25_hits": 0,
            "sentence_hits": 0,
            "mcp_registry_hits": 0,
            "llm_hits": 0,
            "total_searches": 0
        }

        logger.info("HybridToolRegistry ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"  - Sentence-Transformers: {'âœ… ' + self._sentence_model_name if self._sentence_model else 'âŒ ë¹„í™œì„±í™”'}")
        logger.info(f"  - MCP Registry API: {'âœ… í™œì„±í™”' if self._mcp_registry_enabled else 'âŒ ë¹„í™œì„±í™”'}")
        logger.info(f"  - LLM (GPT-5.2): {'âœ… í™œì„±í™”' if self._openai_client else 'âŒ ë¹„í™œì„±í™”'}")

    def _init_sentence_transformers(self) -> None:
        """Sentence-Transformers ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            logger.warning("sentence-transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install sentence-transformers")
            return

        try:
            logger.info(f"Sentence-Transformers ëª¨ë¸ ë¡œë”© ì¤‘: {self._sentence_model_name}")
            self._sentence_model = SentenceTransformer(self._sentence_model_name)
            logger.info("Sentence-Transformers ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        except Exception as e:
            logger.error(f"Sentence-Transformers ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._sentence_model = None

    def _init_openai_client(self) -> None:
        """Azure OpenAI v1 API í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        if self._azure_endpoint and self._api_key:
            try:
                base_url = f"{self._azure_endpoint.rstrip('/')}/openai/v1/"
                self._openai_client = OpenAI(
                    api_key=self._api_key,
                    base_url=base_url,
                    default_query={"api-version": self._api_version}
                )
                logger.info(f"Azure OpenAI v1 API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ (LLMìš©, api-version={self._api_version})")
            except Exception as e:
                logger.warning(f"Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self._openai_client = None
        else:
            logger.warning("Azure OpenAI ìê²© ì¦ëª…ì´ ì—†ì–´ LLM ê²€ìƒ‰ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

    def register(
        self,
        tool: Any,
        name: Optional[str] = None,
        description: Optional[str] = None,
        category: Optional[str] = None,
        tags: Optional[List[str]] = None
    ) -> None:
        """
        ë„êµ¬ë¥¼ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡í•©ë‹ˆë‹¤.

        Args:
            tool: ë“±ë¡í•  ë„êµ¬ (í•¨ìˆ˜, í´ë˜ìŠ¤ ë˜ëŠ” ë„êµ¬ ê°ì²´)
            name: ë„êµ¬ ì´ë¦„ (Noneì´ë©´ ìë™ ì¶”ì¶œ)
            description: ë„êµ¬ ì„¤ëª… (Noneì´ë©´ docstringì—ì„œ ì¶”ì¶œ)
            category: ë„êµ¬ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: "search", "data", "ai")
            tags: ê²€ìƒ‰ì„ ìœ„í•œ ì¶”ê°€ íƒœê·¸ ëª©ë¡
        """
        # ë„êµ¬ ì´ë¦„ ì¶”ì¶œ
        if name is None:
            if hasattr(tool, 'name'):
                name = tool.name
            elif hasattr(tool, '__name__'):
                name = tool.__name__
            else:
                name = str(tool)

        # ì„¤ëª… ì¶”ì¶œ
        if description is None:
            if hasattr(tool, 'description'):
                description = tool.description or ""
            else:
                description = inspect.getdoc(tool) or ""

        # íƒœê·¸ ê²°í•©í•˜ì—¬ ê²€ìƒ‰ ê°€ëŠ¥í•œ ì„¤ëª… ìƒì„±
        tag_string = " ".join(tags) if tags else ""
        category_string = category if category else ""

        # ê²€ìƒ‰ìš© ì¸ë±ìŠ¤ ë¬¸ìì—´ ìƒì„±
        searchable_text = f"{name} {description} {category_string} {tag_string}"

        # ì¤‘ë³µ ë“±ë¡ ì‹œ ê¸°ì¡´ í•­ëª© ì—…ë°ì´íŠ¸
        if name in self._tools:
            idx = self._tool_names.index(name)
            self._descriptions[idx] = searchable_text
        else:
            self._tool_names.append(name)
            self._descriptions.append(searchable_text)

        # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡
        self._tools[name] = tool

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        self._tool_metadata[name] = {
            "description": description,
            "category": category,
            "tags": tags or [],
            "searchable_text": searchable_text
        }

        # ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
        self._rebuild_bm25_index()
        self._sentence_embeddings = None  # lazy rebuild

        logger.debug(f"ë„êµ¬ ë“±ë¡ë¨: {name}")

    def register_batch(
        self,
        tools: List[tuple],
    ) -> None:
        """
        ì—¬ëŸ¬ ë„êµ¬ë¥¼ ì¼ê´„ ë“±ë¡í•©ë‹ˆë‹¤. (ì¸ë±ìŠ¤ ì¬êµ¬ì¶•ì€ ë§ˆì§€ë§‰ì— 1íšŒë§Œ ìˆ˜í–‰)

        Args:
            tools: (tool, name, description, category, tags) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        for entry in tools:
            tool = entry[0]
            name = entry[1] if len(entry) > 1 else None
            description = entry[2] if len(entry) > 2 else None
            category = entry[3] if len(entry) > 3 else None
            tags = entry[4] if len(entry) > 4 else None

            # ë„êµ¬ ì´ë¦„ ì¶”ì¶œ
            if name is None:
                if hasattr(tool, 'name'):
                    name = tool.name
                elif hasattr(tool, '__name__'):
                    name = tool.__name__
                else:
                    name = str(tool)

            # ì„¤ëª… ì¶”ì¶œ
            if description is None:
                if hasattr(tool, 'description'):
                    description = tool.description or ""
                else:
                    description = inspect.getdoc(tool) or ""

            tag_string = " ".join(tags) if tags else ""
            category_string = category if category else ""
            searchable_text = f"{name} {description} {category_string} {tag_string}"

            # ì¤‘ë³µ ë“±ë¡ ì‹œ ê¸°ì¡´ í•­ëª© ì—…ë°ì´íŠ¸
            if name in self._tools:
                idx = self._tool_names.index(name)
                self._descriptions[idx] = searchable_text
            else:
                self._tool_names.append(name)
                self._descriptions.append(searchable_text)

            self._tools[name] = tool
            self._tool_metadata[name] = {
                "description": description,
                "category": category,
                "tags": tags or [],
                "searchable_text": searchable_text
            }

        # ì¸ë±ìŠ¤ ì¬êµ¬ì¶•ì€ ë§ˆì§€ë§‰ì— 1íšŒë§Œ
        self._rebuild_bm25_index()
        self._sentence_embeddings = None
        logger.info(f"ë„êµ¬ ì¼ê´„ ë“±ë¡ ì™„ë£Œ: {len(tools)}ê°œ")

    def _rebuild_bm25_index(self) -> None:
        """BM25 ì¸ë±ìŠ¤ë¥¼ ì¬êµ¬ì¶•í•©ë‹ˆë‹¤."""
        if not self._descriptions:
            self._bm25 = None
            return

        tokenized_corpus = [self._tokenize(desc) for desc in self._descriptions]
        self._bm25 = BM25Okapi(tokenized_corpus)

    def _tokenize(self, text: str) -> List[str]:
        """
        í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤. (í•œêµ­ì–´/ì˜ì–´ ì§€ì›)
        ì‚¬ì „ ì»´íŒŒì¼ëœ ì •ê·œì‹ íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤.
        """
        text = text.lower().replace("_", " ").replace("-", " ")
        tokens = []

        # í•œê¸€ í† í° ì¶”ì¶œ (ìŒì ˆ + ë°”ì´ê·¸ë¨)
        for match in _RE_KOREAN.finditer(text):
            word = match.group()
            tokens.append(word)
            if len(word) >= 2:
                tokens.extend(word[i:i+2] for i in range(len(word) - 1))

        # ì˜ì–´ í† í° ì¶”ì¶œ
        tokens.extend(match.group() for match in _RE_ENGLISH.finditer(text))

        return tokens

    # =========================================================================
    # Sentence-Transformers ê²€ìƒ‰
    # =========================================================================

    def _build_sentence_embeddings(self) -> None:
        """Sentence-Transformers ì„ë² ë”©ì„ êµ¬ì¶•í•©ë‹ˆë‹¤."""
        if self._sentence_embeddings is not None:
            return

        if not self._sentence_model or not self._descriptions:
            return

        logger.info("Sentence-Transformers ì„ë² ë”© êµ¬ì¶• ì¤‘...")
        self._sentence_embeddings = self._sentence_model.encode(
            self._descriptions,
            convert_to_numpy=True,
            show_progress_bar=False
        )
        logger.info(f"Sentence-Transformers ì„ë² ë”© êµ¬ì¶• ì™„ë£Œ: {self._sentence_embeddings.shape}")

    def _sentence_search(self, query: str, top_k: int = 5) -> List[Tuple[str, float]]:
        """Sentence-Transformers ê¸°ë°˜ ì‹œë§¨í‹± ê²€ìƒ‰"""
        if not self._sentence_model:
            return []

        self._build_sentence_embeddings()

        if self._sentence_embeddings is None:
            return []

        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self._sentence_model.encode(
            query,
            convert_to_numpy=True
        )

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = np.dot(self._sentence_embeddings, query_embedding)
        similarities = similarities / (
            np.linalg.norm(self._sentence_embeddings, axis=1) *
            np.linalg.norm(query_embedding) + 1e-8
        )

        # ìƒìœ„ kê°œ ê²°ê³¼
        top_indices = np.argsort(similarities)[::-1][:top_k]

        results = [
            (self._tool_names[i], float(similarities[i]))
            for i in top_indices
        ]

        return results

    # =========================================================================
    # MCP Registry API ê²€ìƒ‰
    # =========================================================================

    def _mcp_registry_search(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """MCP Registry APIì—ì„œ ë„êµ¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        if not self._mcp_registry or not self._mcp_registry_enabled:
            return []

        try:
            servers = self._mcp_registry.search_servers_sync(query, limit)
            return servers
        except Exception as e:
            logger.error(f"MCP Registry ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def discover_external_tools(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """
        MCP Registryì—ì„œ ì™¸ë¶€ ë„êµ¬ë¥¼ ë°œê²¬í•©ë‹ˆë‹¤.

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜

        Returns:
            ë°œê²¬ëœ MCP ì„œë²„ ì •ë³´ ëª©ë¡
        """
        return self._mcp_registry_search(query, limit)

    # =========================================================================
    # LLM ê¸°ë°˜ ê²€ìƒ‰
    # =========================================================================

    def _llm_search(self, query: str, candidates: List[str], top_k: int = 5) -> List[str]:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
        Responses APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ ì„ íƒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        if not self._openai_client:
            return candidates[:top_k]

        # ë„êµ¬ ëª©ë¡ ìƒì„±
        tool_descriptions = []
        for name in candidates:
            metadata = self._tool_metadata.get(name, {})
            desc = metadata.get("description", "")[:200]
            tool_descriptions.append(f"- {name}: {desc}")

        tool_list = "\n".join(tool_descriptions)

        prompt = f"""ì‚¬ìš©ì ì¿¼ë¦¬ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”.

ì‚¬ìš©ì ì¿¼ë¦¬: "{query}"

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
{tool_list}

ìœ„ ë„êµ¬ ì¤‘ì—ì„œ ì‚¬ìš©ìì˜ ìš”ì²­ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ìµœëŒ€ {top_k}ê°œ ì„ íƒí•˜ì—¬,
ë„êµ¬ ì´ë¦„ë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë°˜í™˜í•˜ì„¸ìš”. ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

ì˜ˆì‹œ ì‘ë‹µ: azure_translator_tool, azure_text_analytics_tool"""

        try:
            # Responses API ì‚¬ìš© (v3.0 í†µì¼)
            response = self._openai_client.responses.create(
                model=self._llm_model,
                instructions="ë‹¹ì‹ ì€ ì‚¬ìš©ì ìš”ì²­ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•œêµ­ì–´ì™€ ì˜ì–´ ì¿¼ë¦¬ë¥¼ ëª¨ë‘ ì´í•´í•˜ê³ , ì •í™•í•œ ë„êµ¬ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.",
                input=[{"role": "user", "content": prompt}],
                temperature=0.0,
            )

            result = response.output_text or ""
            selected_tools = [t.strip() for t in result.split(",")]
            valid_tools = [t for t in selected_tools if t in self._tools]

            logger.info(f"LLM ê²€ìƒ‰ ê²°ê³¼: {valid_tools}")
            return valid_tools if valid_tools else candidates[:top_k]

        except Exception as e:
            logger.error(f"LLM ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return candidates[:top_k]

    # =========================================================================
    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    # =========================================================================

    def _bm25_search(self, query: str, top_k: int) -> List[Tuple[str, float]]:
        """BM25 ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        if not self._bm25:
            return []

        tokenized_query = self._tokenize(query)
        scores = self._bm25.get_scores(tokenized_query)

        scored_results = list(zip(self._tool_names, scores))
        scored_results.sort(key=lambda x: x[1], reverse=True)

        return scored_results[:top_k]

    def _hybrid_search(self, query: str, top_k: int) -> List[str]:
        """
        ë‹¤ì¸µ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        Reciprocal Rank Fusion (RRF)ì„ ì‚¬ìš©í•˜ì—¬ BM25ì™€ Sentence-Transformers ê²°ê³¼ë¥¼ í†µí•©í•©ë‹ˆë‹¤.
        """

        # 1ï¸âƒ£ 1ì°¨: BM25 ê²€ìƒ‰ (ë¹ ë¥´ê³  ë¬´ë£Œ)
        bm25_results = self._bm25_search(query, top_k * 2)

        if bm25_results:
            top_score = bm25_results[0][1]

            # BM25 ì ìˆ˜ê°€ ì¶©ë¶„íˆ ë†’ìœ¼ë©´ BM25 ê²°ê³¼ë§Œ ì‚¬ìš©
            if top_score >= self.BM25_CONFIDENCE_THRESHOLD:
                logger.info(f"[BM25 HIT] ì¿¼ë¦¬: '{query}', ìµœê³ ì ìˆ˜: {top_score:.2f}")
                self._search_stats["bm25_hits"] += 1
                return self._format_results(bm25_results[:top_k])

        # 2ï¸âƒ£ 2ì°¨: Sentence-Transformers ê²€ìƒ‰ (ë¡œì»¬, ë‹¤êµ­ì–´)
        if self._sentence_model:
            sentence_results = self._sentence_search(query, top_k * 2)

            if sentence_results:
                top_similarity = sentence_results[0][1]

                if top_similarity >= self.EMBEDDING_SIMILARITY_THRESHOLD:
                    logger.info(f"[SENTENCE HIT] ì¿¼ë¦¬: '{query}', ìµœê³ ìœ ì‚¬ë„: {top_similarity:.3f}")
                    self._search_stats["sentence_hits"] += 1
                    return self._format_results(sentence_results[:top_k])

                # 3ï¸âƒ£ RRF: BM25 + Sentence ê²°ê³¼ë¥¼ Reciprocal Rank Fusionìœ¼ë¡œ í†µí•©
                rrf_scores: Dict[str, float] = {}

                for rank, (name, _score) in enumerate(bm25_results):
                    rrf_scores[name] = rrf_scores.get(name, 0.0) + 1.0 / (self.RRF_K + rank + 1)

                for rank, (name, _score) in enumerate(sentence_results):
                    rrf_scores[name] = rrf_scores.get(name, 0.0) + 1.0 / (self.RRF_K + rank + 1)

                rrf_ranked = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]

                if rrf_ranked:
                    logger.info(f"[RRF FUSION] ì¿¼ë¦¬: '{query}', í†µí•© í›„ë³´: {len(rrf_ranked)}ê°œ")
                    self._search_stats["bm25_hits"] += 1
                    self._search_stats["sentence_hits"] += 1
                    return self._format_results([(name, score) for name, score in rrf_ranked])

        # 4ï¸âƒ£ BM25ë§Œ ìˆëŠ” ê²½ìš° LLM í´ë°±
        if self._openai_client and bm25_results:
            candidates = [name for name, _ in bm25_results[:top_k * 2]]
            logger.info(f"[LLM FALLBACK] ì¿¼ë¦¬: '{query}', í›„ë³´: {len(candidates)}ê°œ")
            self._search_stats["llm_hits"] += 1
            selected = self._llm_search(query, candidates, top_k)
            return self._format_results([(name, 1.0) for name in selected])

        # Fallback: BM25 ê²°ê³¼ ë°˜í™˜
        logger.info(f"[BM25 FALLBACK] ì¿¼ë¦¬: '{query}'")
        self._search_stats["bm25_hits"] += 1
        return self._format_results(bm25_results[:top_k])

    def _format_results(self, results: List[Tuple[str, float]]) -> List[str]:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
        return [
            f"{name}: {self._tool_metadata.get(name, {}).get('description', '').split(chr(10))[0][:150]}"
            for name, _score in results
        ]

    def search(
        self,
        query: str,
        top_k: int = 5,
        strategy: str = "hybrid",
        include_external: bool = False
    ) -> List[str]:
        """
        ë‹¤ì¸µ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ ë„êµ¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

        ê²€ìƒ‰ ì „ëµ:
        1. BM25ë¡œ 1ì°¨ ê²€ìƒ‰ (ë¹ ë¥´ê³  ë¬´ë£Œ)
        2. Sentence-Transformersë¡œ 2ì°¨ ê²€ìƒ‰ (ë¡œì»¬ ë‹¤êµ­ì–´ ì„ë² ë”©)
        3. í•„ìš”ì‹œ LLM ì¬ìˆœìœ„í™” (ê³ ë¹„ìš©, ìµœê³  ì •í™•ë„)
        4. include_external=Trueë©´ MCP Registryì—ì„œ ì™¸ë¶€ ë„êµ¬ ë°œê²¬

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            strategy: ê²€ìƒ‰ ì „ëµ ("bm25", "sentence", "llm", "hybrid")
            include_external: MCP Registryì—ì„œ ì™¸ë¶€ ë„êµ¬ ê²€ìƒ‰ ì—¬ë¶€

        Returns:
            "ë„êµ¬ì´ë¦„: ì„¤ëª… ìš”ì•½" í˜•ì‹ì˜ ë¬¸ìì—´ ëª©ë¡
        """
        self._search_stats["total_searches"] += 1

        results = []

        # ë¡œì»¬ ë„êµ¬ ê²€ìƒ‰
        if self._descriptions:
            if strategy == "bm25":
                results = self._format_results(self._bm25_search(query, top_k))
            elif strategy == "sentence":
                sentence_results = self._sentence_search(query, top_k)
                results = self._format_results(sentence_results)
            elif strategy == "llm":
                all_tools = list(self._tools.keys())
                selected = self._llm_search(query, all_tools, top_k)
                results = self._format_results([(name, 1.0) for name in selected])
            else:
                results = self._hybrid_search(query, top_k)

        # ì™¸ë¶€ ë„êµ¬ ê²€ìƒ‰ (MCP Registry)
        if include_external and self._mcp_registry_enabled:
            external = self._mcp_registry_search(query, top_k)
            if external:
                self._search_stats["mcp_registry_hits"] += 1
                for server in external:
                    name = server.get("name", "unknown")
                    desc = server.get("description", "")[:100]
                    results.append(f"[MCP Registry] {name}: {desc}")

        return results

    def get_tool(self, name: str) -> Optional[Any]:
        """ì´ë¦„ìœ¼ë¡œ ë„êµ¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        return self._tools.get(name)

    def get_tool_metadata(self, name: str) -> Optional[Dict[str, Any]]:
        """ë„êµ¬ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        return self._tool_metadata.get(name)

    def list_all_tools(self) -> List[str]:
        """ë“±ë¡ëœ ëª¨ë“  ë„êµ¬ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return list(self._tools.keys())

    def get_tools_by_category(self, category: str) -> List[str]:
        """íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ë„êµ¬ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return [
            name for name, metadata in self._tool_metadata.items()
            if metadata.get("category") == category
        ]

    def count(self) -> int:
        """ë“±ë¡ëœ ë„êµ¬ ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return len(self._tools)

    def clear(self) -> None:
        """ëª¨ë“  ë„êµ¬ë¥¼ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ì œê±°í•©ë‹ˆë‹¤."""
        self._tools.clear()
        self._descriptions.clear()
        self._tool_names.clear()
        self._tool_metadata.clear()
        self._bm25 = None
        self._sentence_embeddings = None
        logger.info("ë ˆì§€ìŠ¤íŠ¸ë¦¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def get_search_stats(self) -> Dict[str, Any]:
        """ê²€ìƒ‰ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        stats = self._search_stats.copy()
        total = stats["total_searches"]
        if total > 0:
            stats["bm25_ratio"] = f"{stats['bm25_hits'] / total * 100:.1f}%"
            stats["embedding_ratio"] = f"{stats['sentence_hits'] / total * 100:.1f}%"
            stats["embedding_hits"] = stats["sentence_hits"]  # í˜¸í™˜ì„± ë³„ì¹­
            stats["mcp_registry_ratio"] = f"{stats['mcp_registry_hits'] / total * 100:.1f}%"
            stats["llm_ratio"] = f"{stats['llm_hits'] / total * 100:.1f}%"
        else:
            stats["embedding_hits"] = 0
        return stats

    def set_thresholds(
        self,
        bm25_threshold: Optional[float] = None,
        embedding_threshold: Optional[float] = None
    ) -> None:
        """ê²€ìƒ‰ ì„ê³„ê°’ì„ ì„¤ì •í•©ë‹ˆë‹¤."""
        if bm25_threshold is not None:
            self.BM25_CONFIDENCE_THRESHOLD = bm25_threshold
        if embedding_threshold is not None:
            self.EMBEDDING_SIMILARITY_THRESHOLD = embedding_threshold
        logger.info(f"ì„ê³„ê°’ ì„¤ì •ë¨ - BM25: {self.BM25_CONFIDENCE_THRESHOLD}, Embedding: {self.EMBEDDING_SIMILARITY_THRESHOLD}")

    def get_model_info(self) -> Dict[str, Any]:
        """í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            "sentence_model": self._sentence_model_name if self._sentence_model else None,
            "sentence_transformers_available": SENTENCE_TRANSFORMERS_AVAILABLE,
            "mcp_registry_enabled": self._mcp_registry_enabled,
            "llm_model": self._llm_model if self._openai_client else None,
            "tool_count": len(self._tools)
        }


# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
ToolRegistry = HybridToolRegistry

# ì „ì—­ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì¸ìŠ¤í„´ìŠ¤
registry = HybridToolRegistry()
